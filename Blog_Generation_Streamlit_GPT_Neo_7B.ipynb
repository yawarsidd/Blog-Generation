{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "CT2Ys_L-JpWi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbd3b77c-b89b-4fb9-e17d-1033773eef06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.38.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.1.4)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.8.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: watchdog<5,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.0.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install transformers huggingface_hub\n",
        "!pip install pyngrok\n",
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Store the token as an environment variable\n",
        "os.environ[\"HUGGINGFACE_TOKEN\"] = \"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\"  # Replace with your token\n",
        "\n",
        "# Authenticate using the token from the environment variable\n",
        "login(token=os.getenv(\"HUGGINGFACE_TOKEN\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_ZY2hALW6HM",
        "outputId": "0566bdf1-9d84-4007-a95d-cc7e11a3e0de"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import requests\n",
        "import os\n",
        "from bs4 import BeautifulSoup\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Get the Hugging Face token from environment variable\n",
        "hf_token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
        "\n",
        "# Authenticate with Hugging Face\n",
        "login(token=hf_token)\n",
        "\n",
        "# Load the model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-2.7B\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-2.7B\")\n",
        "\n",
        "# Streamlit app\n",
        "st.title(\"Blog Generator\")\n",
        "\n",
        "st.write(\"Input multiple URLs, multiple paragraph indices, and specify the desired word count to generate blogs.\")\n",
        "\n",
        "# Function to scrape specific paragraphs from a webpage\n",
        "def scrape_specific_paragraphs(url, indices):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    paragraphs = soup.find_all('p')\n",
        "\n",
        "    selected_paragraphs = []\n",
        "    for index in indices:\n",
        "        if index < len(paragraphs):\n",
        "            selected_paragraphs.append(paragraphs[index].get_text())\n",
        "        else:\n",
        "            selected_paragraphs.append(f\"Paragraph index {index} out of range.\")\n",
        "\n",
        "    return selected_paragraphs\n",
        "\n",
        "# Function to generate blog using GPT-Neo\n",
        "def get_gpt2_response(specific_paragraphs, no_words):\n",
        "    template = f\"\"\"\n",
        "    You are a blog writer. Generate a blog within {no_words} words based on the following content: {' '.join(specific_paragraphs)}\n",
        "\n",
        "    Structure:\n",
        "    1. **Introduction**: Briefly introduce the topic.\n",
        "    2. **Main Points**:\n",
        "       - Discuss the significance.\n",
        "       - Discuss various perspectives.\n",
        "       - Discuss practical applications.\n",
        "    3. **Conclusion**: Summarize the main ideas.\n",
        "\n",
        "    Make sure the blog is engaging, informative, and easy to read, avoiding any repetition and ensuring a coherent flow of ideas.\n",
        "    \"\"\"\n",
        "\n",
        "    inputs = tokenizer(template, return_tensors=\"pt\", max_length=700, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(**inputs,\n",
        "                                max_length=700,\n",
        "                                num_return_sequences=1,\n",
        "                                temperature=1,\n",
        "                                top_k=50,\n",
        "                                do_sample=True,\n",
        "                                top_p=0.95)\n",
        "\n",
        "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "# Function to scrape and generate blogs\n",
        "def generate_blogs_from_urls(urls_and_indices, no_words):\n",
        "    results = []\n",
        "\n",
        "    def generate_blog(url, indices):\n",
        "        specific_paragraphs = scrape_specific_paragraphs(url, indices)\n",
        "        blog_response = get_gpt2_response(specific_paragraphs, no_words)\n",
        "        results.append(blog_response)\n",
        "\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        futures = [executor.submit(generate_blog, url, indices) for url, indices in urls_and_indices]\n",
        "        for future in futures:\n",
        "            future.result()\n",
        "\n",
        "    return results\n",
        "\n",
        "# User input\n",
        "urls = st.text_area(\"Enter the URLs (one per line)\", 'https://byjus.com/cbse/essay-on-constitution-of-india/\\nhttps://byjus.com/physics/renewable-energy/')\n",
        "indices_input = st.text_area(\"Enter the corresponding paragraph indices for each URL (comma-separated, one set per line)\", \"0,1,2\\n1,2,3\")\n",
        "no_words = st.number_input(\"Enter the number of words for each blog\", value=400)\n",
        "\n",
        "# Process inputs\n",
        "urls_list = urls.splitlines()\n",
        "indices_list = [list(map(int, indices.split(','))) for indices in indices_input.splitlines()]\n",
        "\n",
        "# Ensure the number of URLs and indices match\n",
        "if len(urls_list) != len(indices_list):\n",
        "    st.error(\"The number of URLs and the number of indices sets must match.\")\n",
        "else:\n",
        "    # Start blog generation on button click\n",
        "    if st.button(\"Generate Blogs\"):\n",
        "        urls_and_indices = list(zip(urls_list, indices_list))\n",
        "\n",
        "        with st.spinner(\"Generating blogs...\"):\n",
        "            generated_blogs = generate_blogs_from_urls(urls_and_indices, no_words)\n",
        "\n",
        "        # Display each blog and provide a download option\n",
        "        for i, blog in enumerate(generated_blogs):\n",
        "            st.subheader(f\"Blog {i + 1}\")\n",
        "            st.write(blog)\n",
        "\n",
        "            # Create a download button for the blog\n",
        "            st.download_button(\n",
        "                label=\"Download Blog Post\",\n",
        "                data=blog,\n",
        "                file_name=f\"blog_post_{i + 1}.txt\",\n",
        "                mime=\"text/plain\"\n",
        "            )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QY9VrKVXQk9T",
        "outputId": "56ee6c49-8350-470e-cc15-6359a66d025e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Set the Streamlit port\n",
        "port = 8501\n",
        "\n",
        "# Start ngrok\n",
        "ngrok.set_auth_token(\"2iZTB0eNxBUBRt0WYIlhQeAp1dv_6xHYVAjXCDqn14U9Bek9y\")  # Replace with your ngrok auth token\n",
        "public_url = ngrok.connect(port)\n",
        "print(f\" * ngrok tunnel \\\"{public_url}\\\" -> \\\"http://localhost:{port}\\\"\")\n",
        "\n",
        "# Run Streamlit app\n",
        "!streamlit run app.py &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mnaB91xo-6R",
        "outputId": "d160a059-56b8-4d1d-fbf4-a0fbde487875"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * ngrok tunnel \"NgrokTunnel: \"https://455e-35-185-204-184.ngrok-free.app\" -> \"http://localhost:8501\"\" -> \"http://localhost:8501\"\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.185.204.184:8501\u001b[0m\n",
            "\u001b[0m\n",
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_dmJ_EUKpMZj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}